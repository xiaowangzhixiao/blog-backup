---
title: kafka学习1
toc: true
comments: true
date: 2019-03-12 20:25:16
tags:
- 大数据
category:
- 编程
- Kafka
---

注：本文基于[kafka官网](http://kafka.apache.org)，为学习笔记，或类似官网翻译，边翻译边学习，印象更加深刻

# Introduction

**kafka是一个分布式流平台，那它确切地意味着什么呢？**

一个流平台有以下三个关键能力：
* 发布和订阅消息流， 类似于消息队列或企业的消息传输系统
* 以高容错率的方式对消息流进行存储
* 实时对消息流进行处理

kafka通常用于两大类应用：
* 构建实时流数据管道，可靠地从系统或应用中获取数据
* 构建实时流应用用于转换或响应数据流

<!-- more -->

为了理解kafka是如何做到这些事情的，让我们自上而下地对kafka的能力进行深入研究。

首先了解几个概念：
- kafka以集群的方式跑在一个或多个（可跨多个数据中心的）服务器上。
- kafka集群分类存储消息流，类别称为topic
- 每个记录包含一个key，一个value和一个时间戳

kafka有以下四个核心API：
- 生产者API允许一个应用发布一个数据流到一个或多个kafka的topic中
- 消费者API允许一个应用能够订阅一个或多个topic，并处理产生的那些数据流
- 流数据API允许一个应用作为一个流处理器，从一个或多个topic中消费输入流并产生一个输出流到一个或多个输出topic，有效地将输入流转换为输出流。
- 连接器API允许构建和运行可重用的生产者或消费者，能够连接kafka的topic到现有的应用或数据系统中，例如，一个连接到关系数据库的连接器可能捕获到一个表的每个改变。

![img](http://kafka.apache.org/21/images/kafka-apis.png)


Kafka的客户端和服务器端的通信是由一个简单的，高性能的，语言无关的TCP协议实现的。此协议已经版本化，并与旧版本向后兼容。我们提供了一个Java客户端，但是客户端在许多语言中是可获取的。

## Topics和Logs

让我们首先走进Kafka为数据流提供的核心抽象——Topic。

主题是发布记录的类别或订阅源名称。Topic在Kafka中总是多个订阅用户的；也就是说，一个topic有0个，1个或许多消费者订阅写入它的数据。

对于每个主题，Kafka集群都维护一个分区日志，如下图所示：

![Topic的结构分析](http://kafka.apache.org/21/images/log_anatomy.png)

每个分析都是有序的，不可变的记录序列，不断夫叫道结构化的提交日志中。分区中的记录每个都被分配一个顺序id称为offset用于唯一标识在分片中的每个消息。

Kafka集群持久化所有已发布的记录——不论它们是否被消费掉——使用一个可配置的记忆周期。例如，如果持久化策略设置为两天，那么对于发布了两天的一个消息，它对于消费者是可获取的，在此之后，它将会被删除用于释放空间。Kafka的性能在数据量大小方面是恒定的，因此长时间存储数据不是一个问题。

![消费者与生产者](http://kafka.apache.org/21/images/log_consumer.png)


